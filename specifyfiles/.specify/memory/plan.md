# Implementation Plan: Online Book Foundational Structure

**Feature Branch**: `feat/book-structure-initial`
**Date**: 2025-12-06
**Spec**: `specifyfiles/.specify/memory/spec.md`

## 1. Summary

This plan outlines the technical steps required to create the foundational file and directory structure for the online book, "The Guide to Modern Agentic Development". The implementation will scaffold the main content pages and the complete 13-week modular structure within the Docusaurus `docs` directory. The approach is designed to leverage Docusaurus's autogenerated sidebars for maintainability, directly fulfilling the requirements of the project specification and constitution.

## 2. Constitution Check

This plan strictly adheres to the principles defined in `specifyfiles/.specify/memory/constitution.md`:

*   ✅ **Technical Platform Principle**: All custom components will use TypeScript. The plan focuses on Markdown files, which is platform-agnostic.
*   ✅ **Context7 Principle**: All subsequent automated actions to populate content will adhere to this principle.
*   ✅ **Content Principle**: The core of this plan is to create the 13-week modular structure mandated by the constitution.
*   ✅ **Hardware Principle**: The plan includes the creation of a dedicated file for the "Hardware Requirements".

## 3. Project Structure and Implementation

The following file and directory structure will be created within the `docs` directory.

### 3.1. Top-Level Content Pages

These files will serve as the primary informational pages for the book.

```text
docs/
├── learning-outcomes.md
├── hardware-requirements.md
└── assessments.md
```

### 3.2. Weekly Module Structure

A directory will be created for each of the 13 weeks. This modular structure directly maps to the course syllabus and the content principle of the constitution.

```text
docs/
├── week-1/
│   ├── _category_.json
│   └── introduction.md
├── week-2/
│   ├── _category_.json
│   └── introduction.md
├── week-3/
│   ├── _category_.json
│   └── introduction.md
├── week-4/
│   ├── _category_.json
│   └── introduction.md
├── week-5/
│   ├── _category_.json
│   └── introduction.md
├── week-6/
│   ├── _category_.json
│   └── introduction.md
├── week-7/
│   ├── _category_.json
│   └── introduction.md
├── week-8/
│   ├── _category_.json
│   └── introduction.md
├── week-9/
│   ├── _category_.json
│   └── introduction.md
├── week-10/
│   ├── _category_.json
│   └── introduction.md
├── week-11/
│   ├── _category_.json
│   └── introduction.md
├── week-12/
│   ├── _category_.json
│   └── introduction.md
└── week-13/
    ├── _category_.json
    └── introduction.md
```

### 3.3. Category Configuration

Each `_category_.json` file will contain JSON to define the sidebar label for its respective week, ensuring a clean and ordered navigation experience. For example, `docs/week-1/_category_.json` will contain:

```json
{
  "label": "Week 1 - Introduction to AI and Robotics",
  "position": 1
}
```
*(Note: Labels for weeks 2-13 will be populated with their respective topics during implementation.)*

## 4. Sidebar Strategy

The `sidebars.ts` file is currently configured for autogeneration (`tutorialSidebar: [{type: 'autogenerated', dirName: '.'}]`). This plan will **leverage this feature**. By creating the directory structure outlined above with corresponding `_category_.json` files, the sidebar will be generated automatically.

**This approach requires NO manual edits to `sidebars.ts`** and ensures that the sidebar remains in sync with the file system, making it scalable and easy to maintain.

## 5. High-Level Implementation Steps

1.  **Create Top-Level Pages**: Create the empty markdown files: `learning-outcomes.md`, `hardware-requirements.md`, and `assessments.md` in the `docs/` directory.
2.  **Scaffold Weekly Modules**: Programmatically create the directory structure for `week-1` through `week-13`.
3.  **Populate Categories**: In each weekly directory, create a `_category_.json` file with the appropriate `label` and `position`.
4.  **Create Placeholder Content**: In each weekly directory, create a placeholder `introduction.md` file to ensure the category is not empty.
5.  **Verification**: Run the Docusaurus development server to confirm that all new pages and 13 weekly modules appear correctly in the autogenerated sidebar.

## RAG Chatbot Implementation Plan

**Feature Branch**: `feat/rag-chatbot`
**Spec**: `specifyfiles/.specify/memory/spec.md#RAG-Chatbot-Integration-Feature`

### 1. Summary
This plan details the technical implementation for a RAG (Retrieval-Augmented Generation) chatbot integrated into the Docusaurus site. The chatbot will answer user questions based on the book's content, leveraging a vectorization pipeline, a FastAPI backend, and a React-based frontend component.

### 2. Constitution Check
*   ✅ **Technical Platform Principle**: All custom React components for the frontend will use TypeScript. The backend will use Python with FastAPI, which is a project-approved stack for this feature.
*   ✅ **Context7 Principle**: The vectorization pipeline will be designed to handle versioned documentation by incorporating metadata during the scraping and chunking process. The RAG prompt sent to the LLM will explicitly reference the `Context7` framework to ensure responses are grounded in the correct documentation version.
*   ✅ **Content Principle**: The chatbot's knowledge base will be derived directly from the approved weekly modules and other content pages.
*   ✅ **Hardware Principle**: Not directly applicable to this software feature.

### 3. Stage 1: Vectorization Pipeline
This stage focuses on creating a script (`scripts/vectorize.py`) to process and upload the book's content to the vector store.

**Implementation Steps**:
1.  **Install Dependencies**: Add `openai`, `qdrant-client`, `beautifulsoup4`, `markdown-it-py` to a `requirements.txt` for the pipeline.
2.  **Content Scraper**:
    *   Implement a function to scan the `docs/` directory for all `.md` and `.mdx` files.
    *   For each file, parse the Markdown/MDX content into clean text, stripping away front matter and JSX components to extract readable prose.
3.  **Text Chunking**:
    *   Implement a text splitter (e.g., `RecursiveCharacterTextSplitter` from LangChain or a custom implementation) to break the extracted text into smaller, semantically coherent chunks (e.g., 500-1000 characters with overlap).
    *   Attach metadata to each chunk, including the source file path (e.g., `docs/week-1/introduction.md`) and any relevant headings to aid in citation.
4.  **Embedding Generation**:
    *   Initialize the OpenAI client using an API key from environment variables.
    *   For each text chunk, call the OpenAI Embeddings API (e.g., `text-embedding-3-small`) to generate a vector.
5.  **Qdrant Vector Upload**:
    *   Initialize the Qdrant client using the Cloud URL and API key from environment variables.
    *   Create a Qdrant collection named `book_content_v1` if it doesn't exist, configuring it for the OpenAI embedding vector size (e.g., 1536).
    *   Batch-upload the generated vectors along with their corresponding text chunks and metadata to the collection.

### 4. Stage 2: FastAPI Backend Service - Advanced ChatKit Integration
This stage focuses on creating the FastAPI backend to support the ChatKit Advanced Integration pattern.

**Implementation Steps**:
1.  **Server Setup**:
    *   Create a new directory `api/`.
    *   Set up a `main.py` file with a basic FastAPI application.
    *   Define a `requirements.txt` with `fastapi`, `uvicorn`, `openai`, `qdrant-client`, `pydantic`, `chatkit-sdk`.
2.  **ChatKit Session Endpoint**:
    *   Define a POST endpoint `/api/chatkit/session` (or `/token`).
    *   This endpoint will be responsible for securely generating and returning a short-lived Client Secret (or token) required by the frontend to initialize the ChatKit session.
    *   Implement user authentication/authorization if necessary to secure this endpoint.
3.  **RAG Logic Integration**:
    *   Integrate the RAG logic (Qdrant retrieval, contextual query processing, OpenAI LLM calls) using the ChatKit Python SDK. This can involve defining a ChatKit agent that orchestrates the RAG flow.
    *   Alternatively, if the RAG is hosted externally (e.g., as an OpenAI Agent), reference its Workflow ID within the ChatKit configuration.
    *   The ChatKit agent will handle combining the user's query with retrieved context, constructing the LLM prompt (including `Context7` reference), sending the request to the LLM, and processing the response to extract the answer and source links.

### 5. Stage 3: Docusaurus Frontend Component - ChatKit Advanced Integration
This stage focuses on integrating the ChatKit UI and functionality into the Docusaurus site using the Advanced ChatKit Integration pattern.

**Implementation Steps**:
1.  **Component Scaffolding**:
    *   Create a new React component at `src/components/Chatbot/index.tsx`.
    *   This component will house the entire chat interface.
2.  **ChatKit UI Integration**:
    *   Install the `@openai/chatkit-react` library.
    *   Use components from `@openai/chatkit-react` to build the chat window, message list, and input field.
    *   The component will call the FastAPI session endpoint (`/api/chatkit/session` or `/token`) for authentication and to obtain the Client Secret required for the ChatKit session.
    *   Style the chatbot component to match the Docusaurus theme, potentially floating it in the bottom-right corner of the screen.
3.  **Context Capture Logic**:
    *   Implement a global event listener (e.g., on `mouseup`) in the component.
    *   When the event fires, check if `window.getSelection()` contains any text and if the selection is within the main documentation content area.
    *   If there's a valid selection, store the selected text in the component's state and display a small "Ask about this" button near the selection. This selected text can then be passed to the ChatKit agent as additional context.
4.  **Site Integration**:
    *   Import and render the `<Chatbot />` component in a global layout file, such as `src/theme/Root.tsx`, to ensure it is available on all pages.
